{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\Martijn\\miniconda3\\envs\\BEP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from OCR import *\n",
    "from YoloSplit import *\n",
    "from owlvit import *\n",
    "from CLIPstate import *\n",
    "from state_detection import *\n",
    "from breaking_state_function import *\n",
    "from vehicle_detection import *\n",
    "from chat import *\n",
    "\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Breaking state toevoegen?\n",
    "# TODO: matrix borden detectie/ uitlezen toevoegen\n",
    "# TODO: weg deel toevoegen --> waar de weg is/ hoe die loopt\n",
    "\n",
    "\n",
    "def run_program(input):\n",
    "    # Remove leftover images from previous run of code.\n",
    "    if os.path.exists(\"tri-crop\"):\n",
    "        shutil.rmtree(\"tri-crop\")\n",
    "\n",
    "    dir = os.getcwd()\n",
    "\n",
    "    for f in os.listdir(dir + \"/Crops\"):\n",
    "        os.remove(os.path.join(dir + \"/Crops\", f))\n",
    "\n",
    "    # Set name of image file to analyse\n",
    "    image = input\n",
    "    print(\"testing image \", input)\n",
    "\n",
    "    text_weighted = [\n",
    "        [\"a photo of a person\", 0.25],\n",
    "        [\"a photo of a train\", 0.4],\n",
    "        [\"a photo of a boat\", 0.4],\n",
    "        [\"a photo of a traffic light\", 0.45],\n",
    "        [\"a photo of a stop sign\", 0.4],\n",
    "        [\"a photo of a cat\", 0.4],\n",
    "        [\"a photo of a dog\", 0.4],\n",
    "        [\"a photo of a horse\", 0.4],\n",
    "        [\"a photo of a sheep\", 0.4],\n",
    "        [\"a photo of a cow\", 0.4],\n",
    "        [\"a photo of a traffic cone\", 0.4],\n",
    "        [\"a photo of a traffic sign\", 0.35],\n",
    "        [\"a photo of a ball\", 0.4],\n",
    "        [\"a photo of a tractor\", 0.4],\n",
    "        [\"a photo of a digital traffic sign\", 0.3],\n",
    "        [\"a photo of a digital traffic sign\", 0.4],\n",
    "    ]\n",
    "\n",
    "    weather_list = [\n",
    "        \"a picture of snowy\",\n",
    "        \"a picture of sunny\",\n",
    "        \"a picture of rainy\",\n",
    "        \"a picture of overcast\",\n",
    "        \"a picture of snowy weather\",\n",
    "        \"a picture of sunny weather\",\n",
    "        \"a picture of rainy weather\",\n",
    "        \"a picture of overcast weather\",\n",
    "    ]\n",
    "\n",
    "    location_list = [\n",
    "        \"a picture of a highway\",\n",
    "        \"a picture of a country road\",\n",
    "        \"a picture of a motorway\",\n",
    "        \"a picture of a city\",\n",
    "        \"a picture of a residential area\",\n",
    "    ]\n",
    "\n",
    "    # classes is a list of all the classes shown above\n",
    "\n",
    "    classes_orientation = [\n",
    "        \"car_back\",\n",
    "        \"car_side\",\n",
    "        \"car_front\",\n",
    "        \"bus_back\",\n",
    "        \"bus_side\",\n",
    "        \"bus_front\",\n",
    "        \"truck_back\",\n",
    "        \"truck_side\",\n",
    "        \"truck_front\",\n",
    "        \"motorcycle_back\",\n",
    "        \"motorcycle_side\",\n",
    "        \"motorcycle_front\",\n",
    "        \"bicycle_back\",\n",
    "        \"bicycle_side\",\n",
    "        \"bicycle_front\",\n",
    "    ]\n",
    "\n",
    "    classes_owl = [x[0][13:] for x in text_weighted]\n",
    "\n",
    "    # splits image into 3 parts, outside-view, rear-view, and speed\n",
    "    # saves to tri-crop/predict/crops/outside-view\n",
    "    # saves to tri-crop/predict/crops/rear-view\n",
    "    # saves to tri-crop/predict/crops/speed\n",
    "    tri_crop_results = yolo_tri_crop(\"images/\" + image)\n",
    "\n",
    "    # detects number with OCR in file, specified by its path\n",
    "    car_speed = easyocr_detect(\n",
    "        os.path.join(dir, \"tri-crop/predict/crops/speed/\" + image)\n",
    "    )\n",
    "\n",
    "    # does a zero shot object detection on an image and returns boxes, labels, and scores\n",
    "    owl_boxes, owl_labels, owl_scores = owlvit_object_detect(\n",
    "        text_weighted,\n",
    "        os.path.join(dir, \"tri-crop/predict/crops/outside-view/\" + image),\n",
    "    )\n",
    "\n",
    "    weather, location = CLIP_state_detect(\n",
    "        os.path.join(dir, \"tri-crop/predict/crops/outside-view/\" + image),\n",
    "        weather_list,\n",
    "        location_list,\n",
    "    )\n",
    "\n",
    "    # detecteerd de voertuigen\n",
    "    # detecteerd de voertuigen\n",
    "    image_front = \"tri-crop/predict/crops/outside-view/\" + image\n",
    "\n",
    "    vehicles_detected = vehicle_detection(image_front)\n",
    "\n",
    "    # maakt het dataframe\n",
    "    df = dataframe_bouwen(\n",
    "        owl_labels,\n",
    "        owl_boxes,\n",
    "        owl_scores,\n",
    "        classes_owl,\n",
    "        vehicles_detected,\n",
    "        classes_orientation,\n",
    "        tri_crop_results,\n",
    "        image,\n",
    "    )\n",
    "\n",
    "    # Elke crop maken uit de tabel en foto naam aan tabel toevoegen\n",
    "    fotonaam = []\n",
    "    for row in range(df.shape[0]):\n",
    "        fotonaam = crop_and_save_image(row, df, image_front, fotonaam)\n",
    "    df[\"foto_naam\"] = fotonaam\n",
    "\n",
    "    # bepaald de state een verkeersbord of verkeerslicht\n",
    "\n",
    "    for row in range(df.shape[0]):\n",
    "        if str(df.iloc[row][\"class_naam\"]) == \"traffic sign\":\n",
    "            Traffic_sign(row, df)\n",
    "\n",
    "        elif str(df.iloc[row][\"class_naam\"]) == \"traffic light\":\n",
    "            Traffic_light(row, df)\n",
    "\n",
    "        elif (\n",
    "            str(df.iloc[row][\"state\"]) == \"back\"\n",
    "            and str(df.iloc[row][\"class_naam\"]) == \"car\"\n",
    "        ):\n",
    "            Braking(row, df)\n",
    "\n",
    "    df = position(df, image)\n",
    "\n",
    "    prompt, response = ChatGPT(df, car_speed, location, weather)\n",
    "\n",
    "    print(prompt)\n",
    "    print(response)\n",
    "\n",
    "    text_file = open(\"Output.txt\", \"w\")\n",
    "    text_file.write(prompt)\n",
    "    text_file.write(\"\")\n",
    "    text_file.write(response)\n",
    "    text_file.close()\n",
    "\n",
    "    # reset the variables\n",
    "    df = None\n",
    "    car_speed = None\n",
    "    tri_crop_results = None\n",
    "\n",
    "\n",
    "# df.to_csv(\"C:/Users/Mees/Desktop/dataframe_voor_depth.csv\")\n",
    "\n",
    "# for image in os.listdir(\"images\"):\n",
    "#     input(\"PRESS ENTER TO CONTINUE\")\n",
    "#     run_program(image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Martijn\\Desktop\\coding-projects\\BEP\\GPT-DT\\images\\vraag 14.jpg: 384x640 1 outside-view, 1 rear-view, 1 speed, 121.9ms\n",
      "Speed: 0.0ms preprocess, 121.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mtri-crop\\predict\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing image  vraag 14.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-5-10 Python-3.9.16 torch-2.0.0 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 476 layers, 76226352 parameters, 0 gradients, 110.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvraag 14.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m run_program(image)\n",
      "Cell \u001b[1;32mIn[1], line 110\u001b[0m, in \u001b[0;36mrun_program\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m    107\u001b[0m vehicles_detected \u001b[39m=\u001b[39m vehicle_detection(image_front)\n\u001b[0;32m    109\u001b[0m \u001b[39m# maakt het dataframe\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m df \u001b[39m=\u001b[39m dataframe_bouwen(\n\u001b[0;32m    111\u001b[0m     owl_labels,\n\u001b[0;32m    112\u001b[0m     owl_boxes,\n\u001b[0;32m    113\u001b[0m     owl_scores,\n\u001b[0;32m    114\u001b[0m     classes_owl,\n\u001b[0;32m    115\u001b[0m     vehicles_detected,\n\u001b[0;32m    116\u001b[0m     classes_orientation,\n\u001b[0;32m    117\u001b[0m     tri_crop_results,\n\u001b[0;32m    118\u001b[0m     image,\n\u001b[0;32m    119\u001b[0m )\n\u001b[0;32m    121\u001b[0m \u001b[39m# Elke crop maken uit de tabel en foto naam aan tabel toevoegen\u001b[39;00m\n\u001b[0;32m    122\u001b[0m fotonaam \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Martijn\\Desktop\\coding-projects\\BEP\\GPT-DT\\state_detection.py:56\u001b[0m, in \u001b[0;36mdataframe_bouwen\u001b[1;34m(labels, boxes, scores, texts, x, classes_orientation, tri_crop_result, image)\u001b[0m\n\u001b[0;32m     52\u001b[0m df1[\u001b[39m\"\u001b[39m\u001b[39mclass_naam\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df1[\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     53\u001b[0m df1[\u001b[39m\"\u001b[39m\u001b[39mclass_naam\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreplace(\n\u001b[0;32m     54\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(classes_orientation))), classes_orientation, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     55\u001b[0m )\n\u001b[1;32m---> 56\u001b[0m df1[[\u001b[39m\"\u001b[39m\u001b[39mclass_naam\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m=\u001b[39m df1[\u001b[39m\"\u001b[39;49m\u001b[39mclass_naam\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, expand\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(df1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m df1[\u001b[39m\"\u001b[39m\u001b[39mpredictions\u001b[39m\u001b[39m\"\u001b[39m][row] \u001b[39m<\u001b[39m \u001b[39m0.9\u001b[39m \u001b[39mand\u001b[39;00m df1[\u001b[39m\"\u001b[39m\u001b[39mclass_naam\u001b[39m\u001b[39m\"\u001b[39m][row] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m     59\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcar\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     60\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbicycle\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m     ]:\n",
      "File \u001b[1;32mc:\\Users\\Martijn\\miniconda3\\envs\\BEP\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[1;32mc:\\Users\\Martijn\\miniconda3\\envs\\BEP\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[0;32m    183\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\Martijn\\miniconda3\\envs\\BEP\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstring_\u001b[39;00m \u001b[39mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(data)\n\u001b[0;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_categorical \u001b[39m=\u001b[39m is_categorical_dtype(data\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    183\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_string \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(data\u001b[39m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Users\\Martijn\\miniconda3\\envs\\BEP\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    232\u001b[0m inferred_dtype \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39minfer_dtype(values, skipna\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m inferred_dtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .str accessor with string values!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "image = \"vraag 14.jpg\"\n",
    "run_program(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BEP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
